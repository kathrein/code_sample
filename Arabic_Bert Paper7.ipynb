{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 2,500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "#df = pd.read_csv(\"./Madar6.csv\", delimiter=';', header=None, names=['sentence', 'label'])\n",
    "#df = pd.read_csv(\"./shami.csv\", delimiter=';', header=None, names=['sentence', 'label'],encoding = \"utf-8\")\n",
    "#df = pd.read_csv(\"/Users/xabuka/PycharmProjects/Shami-Sentiment-Analyzer/data/ASTD/padic.csv\", delimiter=';', header=None, names=['sentence', 'label'],encoding = \"utf-8\")\n",
    "\n",
    "#df = pd.read_csv(\"./train_Arabic_tweets.tsv\", delimiter='\\t', header=None, names=['label_tag','sentence', 'label'],encoding = \"utf-16\")\n",
    "#df = pd.read_csv(\"./40000-Egyptian-tweets.csv\", delimiter=';', header=None, names=['sentence', 'label'],encoding = \"utf-8\")\n",
    "#df = pd.read_csv(\"./2_labr_train.csv\", delimiter=';', header=None, names=['label','sentence'],encoding = \"utf-8\")\n",
    "df = pd.read_csv(\"/Users/xabuka/PycharmProjects/Shami-Sentiment-Analyzer/data/ASTD/astd.csv\", delimiter=';', header=None, names=['sentence','label_tag', 'label'],encoding = \"utf-8\")\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "31951\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label_tag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>#اعرفوهم #انقلاب_مصر #يسقط_حكم_العسكر #الداخلي...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>اقتحام السفارة مش سلمي</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>#أردوغان معادي للإسلام يقود \"دولة فاجرة وفاسقة\"</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>من يوقف قانون العزل ومن يجمد بلاغات الفساد ضد ...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>ده مش جيل 54 زى ما هيكل كان فاكر ده جيل 25 ينا...</td>\n",
       "      <td>POS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>كما تهمنا #مصر تعنينا #دمشق وكما تُشقينا #غزة ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>اللهم امطر على قبر #محمد حسين جمعه وعلى قبور ج...</td>\n",
       "      <td>POS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>#أحمد_موسى ما استطاع الرد على #باسم_يوسف وقد ج...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>الرضا بماا كتبه الله لك~ يجعل لك الحياة كما تريد♡</td>\n",
       "      <td>POS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>اللغة تراث</td>\n",
       "      <td>POS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence label_tag  label\n",
       "1485  #اعرفوهم #انقلاب_مصر #يسقط_حكم_العسكر #الداخلي...       NEG      0\n",
       "1615                             اقتحام السفارة مش سلمي       NEG      0\n",
       "1894    #أردوغان معادي للإسلام يقود \"دولة فاجرة وفاسقة\"       NEG      0\n",
       "943   من يوقف قانون العزل ومن يجمد بلاغات الفساد ضد ...       NEG      0\n",
       "601   ده مش جيل 54 زى ما هيكل كان فاكر ده جيل 25 ينا...       POS      1\n",
       "1061  كما تهمنا #مصر تعنينا #دمشق وكما تُشقينا #غزة ...       POS      1\n",
       "398   اللهم امطر على قبر #محمد حسين جمعه وعلى قبور ج...       POS      1\n",
       "991   #أحمد_موسى ما استطاع الرد على #باسم_يوسف وقد ج...       NEG      0\n",
       "1768  الرضا بماا كتبه الله لك~ يجعل لك الحياة كما تريد♡       POS      1\n",
       "1041                                         اللغة تراث       POS      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences = df.sentence.values\n",
    "df.label = pd.factorize(df.label)[0]\n",
    "all_labels = df.label.values\n",
    "\n",
    "print(len(all_sentences))\n",
    "#if we have two seperated files for train and test, pleease commit the following code\n",
    "# and remove word all_ from the previous two lines.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# as we have separate test set , then no need to split here\n",
    "train_df, test_df = train_test_split(df, test_size=0.1)\n",
    "#train_df = df\n",
    "X_train = train_df.sentence.values\n",
    "\n",
    "#convert labels to int\n",
    "#train_df.label = pd.factorize(train_df.label)[0]\n",
    "\n",
    "#print(train_df.sample(10))\n",
    "y_train = train_df.label.values\n",
    "#print(labels[0:10])\n",
    "print(len(sentences))\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = test_df\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "X_test = test_df.sentence.values\n",
    "\n",
    "#df.label = pd.factorize(df.label)[0]\n",
    "y_test = test_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "def train_model(model, data, targets):\n",
    "    text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', model),\n",
    "    ])\n",
    "    text_clf.fit(data, targets)\n",
    "    return text_clf\n",
    "def get_accuracy(trained_model,X, y):\n",
    "    predicted = trained_model.predict(X)\n",
    "    accuracy = np.mean(predicted == y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset accuracy with DecisionTreeClassifier: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "trained_clf_decision_tree = train_model(DecisionTreeClassifier(), X_train, y_train)\n",
    "accuracy = get_accuracy(trained_clf_decision_tree,X_test, y_test)\n",
    "print(f\"Test dataset accuracy with DecisionTreeClassifier: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset accuracy with MultinomialNB: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "trained_clf_multinomial_nb = train_model(MultinomialNB(), X_train, y_train)\n",
    "accuracy = get_accuracy(trained_clf_multinomial_nb,X_test, y_test)\n",
    "print(f\"Test dataset accuracy with MultinomialNB: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset accuracy with LinearSVC: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "trained_clf_linearSVC = train_model(LinearSVC(), X_train, y_train)\n",
    "accuracy = get_accuracy(trained_clf_linearSVC,X_test, y_test)\n",
    "print(f\"Test dataset accuracy with LinearSVC: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset accuracy with RandomForestClassifier: 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "trained_clf_random_forest = train_model(RandomForestClassifier(), X_train, y_train)\n",
    "accuracy = get_accuracy(trained_clf_random_forest,X_test, y_test)\n",
    "print(f\"Test dataset accuracy with RandomForestClassifier: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning Arabic Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
